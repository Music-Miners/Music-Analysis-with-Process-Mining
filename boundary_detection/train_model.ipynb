{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://verovio.humdrum.org/?file=essen/europa/deutschl/altdeu2/deut4207.krn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"data_germany_1\",\"data_germany_2\",\"data_germany_3\",\"data_germany_4\",\"data_germany_5\",\"data_germany_6\",\"data_germany_7\", \"data_germany_8\", \"data_germany_9\", \"data_germany_10\", \"data_germany_11\"]\n",
    "for file in files:\n",
    "    with open('../data/data_2/{}.pkl'.format(file), 'rb') as handle:\n",
    "        data.extend(pickle.load(handle))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_input = []\n",
    "durations_input = []\n",
    "phrases_input = []\n",
    "\n",
    "for piece in data:\n",
    "    notes = piece[0]\n",
    "    notes_input.append(129) # START = 129\n",
    "    notes_input.extend(notes)\n",
    "\n",
    "    durations = piece[1]\n",
    "    durations_input.append(0)\n",
    "    durations_input.extend(durations)\n",
    "\n",
    "    phrases = piece[2]\n",
    "    phrases_input.append(0)\n",
    "    phrases_input.extend(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_length = dict()\n",
    "counter = 0\n",
    "for i in range(len(phrases_input)):\n",
    "    counter+=1\n",
    "    if phrases_input[i] == 1:\n",
    "        # print(i)\n",
    "        # print(phrases_input)\n",
    "        # print(counter)\n",
    "        if counter in phrases_length.keys():\n",
    "            phrases_length[counter] += 1\n",
    "        else:\n",
    "            phrases_length[counter] = 1\n",
    "        counter = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(phrases_length.keys())\n",
    "keys.sort()\n",
    "sorted_dict = { key : phrases_length[key] for key in keys}\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of the notes_input: {}\".format(len(notes_input)))\n",
    "print(\"Twenty first elements: {}\".format(notes_input[:20]))\n",
    "print(\"Length of the durations_input: {}\".format(len(durations_input)))\n",
    "print(\"Twenty first elements: {}\".format(durations_input[:20]))\n",
    "print(\"Length of the phrases_input: {}\".format(len(phrases_input)))\n",
    "print(\"Twenty first elements: {}\".format(phrases_input[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dict()\n",
    "for i in range(len(notes_input)):\n",
    "    if phrases_input[i] == 1:\n",
    "        if notes_input[i] not in result.keys():\n",
    "            result[notes_input[i]] = 1\n",
    "        else:\n",
    "            result[notes_input[i]] +=1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(notes_input)):\n",
    "    if phrases_input[i] == 1 and notes_input[i] == 128:\n",
    "        phrases_input[i] = 0\n",
    "        k = i - 1\n",
    "        while k > 0:\n",
    "            if notes_input[k] == 128:\n",
    "                k -= 1\n",
    "            else:\n",
    "                phrases_input[k] = 1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dict()\n",
    "for i in range(len(notes_input)):\n",
    "    if phrases_input[i] == 1:\n",
    "        if notes_input[i] not in result.keys():\n",
    "            result[notes_input[i]] = 1\n",
    "        else:\n",
    "            result[notes_input[i]] +=1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_to_int = {}\n",
    "int_to_duration = {}\n",
    "notes_to_int = {}\n",
    "int_to_notes = {}\n",
    "phrases_to_int = {}\n",
    "int_to_phrases = {}\n",
    "for index, duration in enumerate(sorted(set(durations_input))):\n",
    "    durations_to_int[duration] = index\n",
    "    int_to_duration[index] = duration\n",
    "\n",
    "for index, note in enumerate(sorted(set(notes_input))):\n",
    "    notes_to_int[note] = index\n",
    "    int_to_notes[index] = note\n",
    "\n",
    "for index, phrase in enumerate(sorted(set(phrases_input))):\n",
    "    phrases_to_int[phrase] = index\n",
    "    int_to_phrases[index] = phrase\n",
    "\n",
    "durations_network_input = [ durations_to_int[duration] for duration in durations_input ]\n",
    "notes_network_input = [ notes_to_int[note] for note in notes_input ]\n",
    "phrases_network_input = [ phrases_to_int[phrase] for phrase in phrases_input ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of the notes_input: {}\".format(len(notes_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(notes_network_input[:20]))\n",
    "print(\"Length of the durations_input: {}\".format(len(durations_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(durations_network_input[:20]))\n",
    "print(\"Length of the phrases_input: {}\".format(len(phrases_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(phrases_network_input[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = len(notes_to_int)\n",
    "n_durations = len(durations_to_int)\n",
    "n_phrases = len(phrases_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of distinct notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct durations: {}\".format(n_durations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary.pkl', 'wb') as file:\n",
    "    dictionary = { \"durations_to_int\" : durations_to_int, \"int_to_duration\" : int_to_duration, \"notes_to_int\" : notes_to_int, \"int_to_notes\" : int_to_notes, \"phrases_to_int\" : phrases_to_int, \"int_to_phrases\" : int_to_phrases }\n",
    "    # A new file will be created\n",
    "    pickle.dump(dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import note, chord\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from RNNmodel import prepare_sequences, create_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 8\n",
    "network_input, network_output = prepare_sequences(notes_network_input, durations_network_input, phrases_network_input, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('note input')\n",
    "print(network_input[0][0])\n",
    "print('duration input')\n",
    "print(network_input[1][0])\n",
    "print('phrases_output')\n",
    "print(network_output[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "rnn_units = 256\n",
    "use_attention = True\n",
    "model, att_model = create_network(n_notes, n_durations, n_phrases, embed_size, rnn_units, use_attention)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weights_folder = \"weights\" #os.path.join(run_folder, 'weights')\n",
    "# model.load_weights(os.path.join(weights_folder, \"weights.h5\"))\n",
    "\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 10\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint1\n",
    "    , checkpoint2\n",
    "    , early_stopping\n",
    " ]\n",
    "\n",
    "model.save_weights(os.path.join(weights_folder, \"weights.h5\"))\n",
    "model.fit(network_input, network_output\n",
    "          , epochs=2000000, batch_size=32\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
