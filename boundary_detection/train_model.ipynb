{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 22:31:22.582613: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-03 22:31:25.245360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 22:31:31.378223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-03 22:31:31.802538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-03 22:31:31.802745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Input, Dense, Activation, Embedding, Concatenate, Reshape\n",
    "from keras.layers import RepeatVector, Permute\n",
    "from keras.layers import Multiply, Lambda\n",
    "import keras.backend as K \n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from the Oskar Kolberg's Dataset\n",
    "https://webesac.pcss.pl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "files = [\"data_kolberg\"]\n",
    "for file in files:\n",
    "    with open(\"../data/Oskar Kolberg's Dataset/{}.pkl\".format(file), 'rb') as handle:\n",
    "        data.extend(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19092"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_pieces = len(data)\n",
    "number_of_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove too long or too short pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces_lengths = dict()\n",
    "for piece in data:\n",
    "    if len(piece[0]) in pieces_lengths.keys():\n",
    "        pieces_lengths[len(piece[0])] += 1\n",
    "    else:\n",
    "        pieces_lengths[len(piece[0])] = 1\n",
    "\n",
    "pieces_lengths = sorted(pieces_lengths.items(), key=lambda x: x[1], reverse=True)\n",
    "pieces_lengths = [ (length, count) for length, count in pieces_lengths if count > 0.02 * number_of_pieces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 1089),\n",
       " (28, 981),\n",
       " (36, 714),\n",
       " (34, 693),\n",
       " (30, 650),\n",
       " (26, 639),\n",
       " (24, 600),\n",
       " (29, 599),\n",
       " (33, 573),\n",
       " (38, 559),\n",
       " (31, 558),\n",
       " (40, 553),\n",
       " (37, 524),\n",
       " (35, 513),\n",
       " (27, 478),\n",
       " (42, 460),\n",
       " (39, 457),\n",
       " (41, 411)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces_lengths = [ length for length, count in pieces_lengths ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = min(pieces_lengths)\n",
    "upper_bound = max(pieces_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The length of the shortest piece\n",
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The length of the longest piece\n",
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = []\n",
    "for piece in data:\n",
    "    if len(piece[0]) in pieces_lengths:\n",
    "        cleaned_data.append(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11051"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cleaned_data\n",
    "number_of_pieces = len(data)\n",
    "number_of_pieces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove too long or too short phrases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the range of the most common lengths of phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_data = []\n",
    "bars_data = [] \n",
    "phrases_data = []\n",
    "\n",
    "for piece in data:\n",
    "    notes_data.extend(piece[0])\n",
    "    bars_data.extend(piece[2])\n",
    "    phrases_data.extend(piece[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 64, 67, 67, 67, 70, 67, 64, 65, 69, 65, 62, 60, 64, 67, 60, 60, 64, 67, 67, 67, 71, 72, 67, 67, 69, 65, 62, 64, 60]\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0])\n",
    "print(data[0][2])\n",
    "print(data[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 3159),\n",
       " (8, 2811),\n",
       " (16, 2551),\n",
       " (12, 2328),\n",
       " (13, 1993),\n",
       " (15, 1846),\n",
       " (10, 1836),\n",
       " (9, 1781),\n",
       " (7, 1618),\n",
       " (18, 1458),\n",
       " (17, 1386),\n",
       " (11, 1126)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_lengths = dict()\n",
    "counter = 0\n",
    "for i in range(len(phrases_data)):\n",
    "    counter+=1\n",
    "    if phrases_data[i] == 1:\n",
    "        if counter in phrases_lengths.keys():\n",
    "            phrases_lengths[counter] += 1\n",
    "        else:\n",
    "            phrases_lengths[counter] = 1\n",
    "        counter = 0\n",
    "\n",
    "phrases_lengths = sorted(phrases_lengths.items(), key=lambda x: x[1], reverse=True)\n",
    "phrases_lengths = [ (length, count) for length, count in phrases_lengths if count > 0.1 * number_of_pieces]\n",
    "phrases_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_lengths = [ length for length, count in phrases_lengths ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove pieces with irregular phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = phrases_lengths[0]\n",
    "lower_bound = min(phrases_lengths)\n",
    "upper_bound = max(phrases_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most common phrases length ==> the lenght of a sequence\n",
    "seq_len = 36\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shortest phrase lenght we consider\n",
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The longest phrase lenght we consider\n",
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = []\n",
    "\n",
    "for piece in data:\n",
    "    current_phrase_length = 0\n",
    "    skip = False\n",
    "\n",
    "    if len(piece[0]) < upper_bound:\n",
    "        skip = True\n",
    "    else:\n",
    "        for i, digit in enumerate(piece[3]):\n",
    "            current_phrase_length += 1\n",
    "            if digit == 1:\n",
    "                # Skip pieces with irregular phrases\n",
    "                if current_phrase_length not in phrases_lengths:\n",
    "                    skip = True\n",
    "                    break\n",
    "                # Skip pieces with phrases that don't end at the end of a measure\n",
    "                if piece[2][i] != 1:\n",
    "                    skip = True\n",
    "                    break\n",
    "                current_phrase_length = 0\n",
    "    if skip:\n",
    "        continue\n",
    "    else:\n",
    "        pieces.append(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6857"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_pieces = len(pieces)\n",
    "number_of_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pieces\n",
    "# save the train and test data to pickle files\n",
    "with open(\"../data/Oskar Kolberg's Dataset/data_kolberg_cleaned.pkl\", 'wb') as handle:\n",
    "    pickle.dump(cleaned_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "pieces_train, pieces_test = train_test_split(pieces, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5485, 1372)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pieces_train), len(pieces_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and test data to pickle files\n",
    "with open(\"../data/Oskar Kolberg's Dataset/train/pieces_train.pkl\", 'wb') as handle:\n",
    "    pickle.dump(pieces_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"../data/Oskar Kolberg's Dataset/test/pieces_test.pkl\", 'wb') as handle:\n",
    "    pickle.dump(pieces_test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_input = []\n",
    "bars_input = []\n",
    "phrases_input = []\n",
    "\n",
    "for piece in pieces_train:\n",
    "    notes = piece[0]\n",
    "    notes_input.extend([129 for i in range(seq_len)])\n",
    "    notes_input.extend(notes)\n",
    "\n",
    "    bars = piece[2]\n",
    "    bars_input.extend([0 for i in range(seq_len)])\n",
    "    bars_input.extend(bars)\n",
    "    \n",
    "    phrases = piece[3]\n",
    "    phrases_input.extend([0 for i in range(seq_len)])\n",
    "    phrases_input.extend(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the notes_input: 369729\n",
      "Twenty first elements: [129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129]\n",
      "Length of the bars_input: 369729\n",
      "Twenty first elements: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Length of the phrases_input: 369729\n",
      "Twenty first elements: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the notes_input: {}\".format(len(notes_input)))\n",
    "print(\"Twenty first elements: {}\".format(notes_input[:20]))\n",
    "print(\"Length of the bars_input: {}\".format(len(bars_input)))\n",
    "print(\"Twenty first elements: {}\".format(bars_input[:20]))\n",
    "print(\"Length of the phrases_input: {}\".format(len(phrases_input)))\n",
    "print(\"Twenty first elements: {}\".format(phrases_input[:20]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map durations and notes to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_int = {}\n",
    "int_to_notes = {}\n",
    "phrases_to_int = {}\n",
    "int_to_phrases = {}\n",
    "bars_to_int = {}\n",
    "int_to_bars = {}\n",
    "\n",
    "for index, note in enumerate(sorted(set(notes_data).union({129}))):\n",
    "    notes_to_int[note] = index\n",
    "    int_to_notes[index] = note\n",
    "\n",
    "for index, phrase in enumerate(sorted(set(phrases_data))):\n",
    "    phrases_to_int[phrase] = index\n",
    "    int_to_phrases[index] = phrase\n",
    "\n",
    "for index, bar in enumerate(sorted(set(bars_data))):\n",
    "    bars_to_int[bar] = index\n",
    "    int_to_bars[index] = bar\n",
    "\n",
    "notes_network_input = [ notes_to_int[note] for note in notes_input ]\n",
    "bars_network_input = [ bars_to_int[bar] for bar in bars_input ]\n",
    "phrases_network_input = [ phrases_to_int[phrase] for phrase in phrases_input ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 89, 128, 129]\n"
     ]
    }
   ],
   "source": [
    "# Before\n",
    "print(sorted(set(notes_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41]\n"
     ]
    }
   ],
   "source": [
    "# After\n",
    "print(sorted(set(notes_network_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the notes_input: 369729\n",
      "Twenty first elements: [41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "Length of the bars_input: 369729\n",
      "Twenty first elements: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Length of the phrases_input: 369729\n",
      "Twenty first elements: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the notes_input: {}\".format(len(notes_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(notes_network_input[:20]))\n",
    "print(\"Length of the bars_input: {}\".format(len(bars_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(bars_network_input[:20]))\n",
    "print(\"Length of the phrases_input: {}\".format(len(phrases_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(phrases_network_input[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = len(notes_to_int)\n",
    "n_phrases = len(phrases_to_int)\n",
    "n_bars = len(bars_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct notes: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of distinct notes: {}\".format(n_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary.pkl', 'wb') as file:\n",
    "    dictionary = { \"notes_to_int\" : notes_to_int, \"int_to_notes\" : int_to_notes, \"phrases_to_int\" : phrases_to_int, \"int_to_phrases\" : int_to_phrases, \"bars_to_int\" : bars_to_int, \"int_to_bars\" : int_to_bars }\n",
    "    # A new file will be created\n",
    "    pickle.dump(dictionary, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare network input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, bars, phrases, seq_len = 32):\n",
    "\n",
    "    notes_input = []\n",
    "    bars_input = []\n",
    "    phrases_output = []\n",
    "\n",
    "    for i in range(len(notes) - seq_len):\n",
    "        notes_input.append(notes[i:i + seq_len])\n",
    "        bars_input.append(bars[i:i + seq_len])\n",
    "\n",
    "        phrases_output.append(phrases[i + seq_len])\n",
    "\n",
    "    n_patterns = len(notes_input)\n",
    "\n",
    "    notes_input = np.reshape(notes_input, (n_patterns, seq_len))\n",
    "    bars_input = np.reshape(bars_input, (n_patterns, seq_len))\n",
    "    network_input = [notes_input, bars_input]\n",
    "\n",
    "    phrases_output = np_utils.to_categorical(phrases_output, num_classes=2)\n",
    "    network_output = [phrases_output]\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input, network_output = prepare_sequences(notes_network_input, bars_network_input, phrases_network_input, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note input\n",
      "[41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41 41 41 41 41 41 41]\n",
      "bars input\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "phrases_output\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('note input')\n",
    "print(network_input[0][0])\n",
    "print('bars input')\n",
    "print(network_input[1][0])\n",
    "print('phrases_output')\n",
    "print(network_output[0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(n_notes, n_bars, n_phrases, embed_size = 100, rnn_units = 256, use_attention = False):\n",
    "\n",
    "    notes_in = Input(shape = (None,))\n",
    "    bars_in = Input(shape = (None,))\n",
    "\n",
    "    x1 = Embedding(n_notes, embed_size)(notes_in)\n",
    "    x3 = Embedding(n_bars, embed_size)(bars_in)\n",
    "\n",
    "    x = Concatenate()([x1,x3])\n",
    "\n",
    "    x = LSTM(rnn_units, return_sequences=True)(x)\n",
    "\n",
    "    if use_attention:\n",
    "\n",
    "        x = LSTM(rnn_units, return_sequences=True)(x)\n",
    "\n",
    "        e = Dense(1, activation='tanh')(x)\n",
    "        e = Reshape([-1])(e)\n",
    "        alpha = Activation('softmax')(e)\n",
    "\n",
    "        alpha_repeated = Permute([2, 1])(RepeatVector(rnn_units)(alpha))\n",
    "\n",
    "        c = Multiply()([x, alpha_repeated])\n",
    "        c = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c)\n",
    "    \n",
    "    else:\n",
    "        c = LSTM(rnn_units)(x)\n",
    "                                    \n",
    "    phrases_out = Dense(n_phrases, activation = 'softmax', name = 'phrase')(c)\n",
    "   \n",
    "    model = Model([notes_in, bars_in], [phrases_out])\n",
    "    \n",
    "\n",
    "    if use_attention:\n",
    "        att_model = Model([notes_in, bars_in], alpha)\n",
    "    else:\n",
    "        att_model = None\n",
    "\n",
    "\n",
    "    opti = RMSprop(lr = 0.001)\n",
    "    model.compile(loss=['binary_crossentropy', 'binary_crossentropy'], optimizer=opti)\n",
    "\n",
    "    return model, att_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 01:35:10.096468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 01:35:10.098734: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 01:35:10.100232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 42)     1764        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 42)     84          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, 84)     0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, None, 256)    349184      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, None, 256)    525312      ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 1)      257         ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, None)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None)         0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 256, None)    0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, None, 256)    0           ['repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, None, 256)    0           ['lstm_1[0][0]',                 \n",
      "                                                                  'permute[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 256)          0           ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " phrase (Dense)                 (None, 2)            514         ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 877,115\n",
      "Trainable params: 877,115\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 01:35:10.347743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 01:35:10.349942: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 01:35:10.351454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "embed_size = 42\n",
    "rnn_units = 256\n",
    "use_attention = True\n",
    "model, att_model = create_network(n_notes, n_bars, n_phrases, embed_size, rnn_units, use_attention)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 01:35:10.923447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 01:35:10.925956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 01:35:10.927751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-29 01:35:11.152543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 01:35:11.154824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 01:35:11.156528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-29 01:35:12.575345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 01:35:12.577876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 01:35:12.579759: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-29 01:35:12.828763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 01:35:12.831284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 01:35:12.833150: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2958/2958 [==============================] - ETA: 0s - loss: 0.1290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 01:43:04.697218: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 01:43:04.699195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 01:43:04.700655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-29 01:43:04.922478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 01:43:04.924651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 01:43:04.926125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2958/2958 [==============================] - 520s 174ms/step - loss: 0.1290 - val_loss: 0.1204\n",
      "Epoch 2/30\n",
      "2958/2958 [==============================] - 527s 178ms/step - loss: 0.1099 - val_loss: 0.1006\n",
      "Epoch 3/30\n",
      "2958/2958 [==============================] - 536s 181ms/step - loss: 0.0965 - val_loss: 0.0936\n",
      "Epoch 4/30\n",
      "2958/2958 [==============================] - 537s 182ms/step - loss: 0.0830 - val_loss: 0.0790\n",
      "Epoch 5/30\n",
      "2958/2958 [==============================] - 534s 180ms/step - loss: 0.0770 - val_loss: 0.0794\n",
      "Epoch 6/30\n",
      "2958/2958 [==============================] - 525s 177ms/step - loss: 0.0744 - val_loss: 0.0738\n",
      "Epoch 7/30\n",
      "2958/2958 [==============================] - 525s 178ms/step - loss: 0.0719 - val_loss: 0.0737\n",
      "Epoch 8/30\n",
      "2958/2958 [==============================] - 529s 179ms/step - loss: 0.0703 - val_loss: 0.0713\n",
      "Epoch 9/30\n",
      "2958/2958 [==============================] - 530s 179ms/step - loss: 0.0688 - val_loss: 0.0704\n",
      "Epoch 10/30\n",
      "2958/2958 [==============================] - 530s 179ms/step - loss: 0.0677 - val_loss: 0.0714\n",
      "Epoch 11/30\n",
      "2958/2958 [==============================] - 538s 182ms/step - loss: 0.0667 - val_loss: 0.0720\n",
      "Epoch 12/30\n",
      "2958/2958 [==============================] - 530s 179ms/step - loss: 0.0659 - val_loss: 0.0722\n",
      "Epoch 13/30\n",
      "2958/2958 [==============================] - 530s 179ms/step - loss: 0.0650 - val_loss: 0.0723\n",
      "Epoch 14/30\n",
      "2958/2958 [==============================] - 547s 185ms/step - loss: 0.0643 - val_loss: 0.0717\n",
      "Epoch 15/30\n",
      "2958/2958 [==============================] - 568s 192ms/step - loss: 0.0643 - val_loss: 0.0711\n",
      "Epoch 16/30\n",
      "2958/2958 [==============================] - 536s 181ms/step - loss: 0.0637 - val_loss: 0.0704\n",
      "Epoch 17/30\n",
      "2958/2958 [==============================] - 536s 181ms/step - loss: 0.0632 - val_loss: 0.0731\n",
      "Epoch 18/30\n",
      "2958/2958 [==============================] - 535s 181ms/step - loss: 0.0627 - val_loss: 0.0702\n",
      "Epoch 19/30\n",
      "2958/2958 [==============================] - 530s 179ms/step - loss: 0.0632 - val_loss: 0.0734\n",
      "Epoch 20/30\n",
      "2958/2958 [==============================] - 533s 180ms/step - loss: 0.0637 - val_loss: 0.0712\n",
      "Epoch 21/30\n",
      "2958/2958 [==============================] - 525s 177ms/step - loss: 0.0628 - val_loss: 0.0713\n",
      "Epoch 22/30\n",
      "2958/2958 [==============================] - 522s 176ms/step - loss: 0.0629 - val_loss: 0.0702\n",
      "Epoch 23/30\n",
      "2958/2958 [==============================] - 525s 178ms/step - loss: 0.0628 - val_loss: 0.0710\n",
      "Epoch 24/30\n",
      "2958/2958 [==============================] - 532s 180ms/step - loss: 0.0628 - val_loss: 0.0716\n",
      "Epoch 25/30\n",
      "2958/2958 [==============================] - 541s 183ms/step - loss: 0.0634 - val_loss: 0.0712\n",
      "Epoch 26/30\n",
      "2958/2958 [==============================] - 535s 181ms/step - loss: 0.0625 - val_loss: 0.0712\n",
      "Epoch 27/30\n",
      "2958/2958 [==============================] - 542s 183ms/step - loss: 0.0635 - val_loss: 0.0720\n",
      "Epoch 28/30\n",
      "2958/2958 [==============================] - 537s 181ms/step - loss: 0.0645 - val_loss: 0.0723\n",
      "Epoch 29/30\n",
      "2958/2958 [==============================] - 536s 181ms/step - loss: 0.0639 - val_loss: 0.0711\n",
      "Epoch 30/30\n",
      "2958/2958 [==============================] - 542s 183ms/step - loss: 0.0647 - val_loss: 0.0740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcae9e1cd00>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_folder = \"weights\"\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 10\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint1\n",
    "    , checkpoint2\n",
    "    , early_stopping\n",
    " ]\n",
    "\n",
    "model.save_weights(os.path.join(weights_folder, \"weights.h5\"))\n",
    "model.fit(network_input, network_output\n",
    "          , epochs=30\n",
    "          , batch_size=100\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "bed620aa74556e6e6bd3b11d1105b690de0e70139218f60bfc1519e47e474149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
