{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 20:51:34.257028: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 20:51:37.610128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 20:51:39.379682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 20:51:39.793952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 20:51:39.794011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://verovio.humdrum.org/?file=essen/europa/deutschl/altdeu2/deut4207.krn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"data_germany_1\",\"data_germany_2\",\"data_germany_3\",\"data_germany_4\",\"data_germany_5\",\"data_germany_6\",\"data_germany_7\", \"data_germany_8\", \"data_germany_9\", \"data_germany_10\", \"data_germany_11\"]\n",
    "for file in files:\n",
    "    with open('data/data/{}.pkl'.format(file), 'rb') as handle:\n",
    "        data.extend(pickle.load(handle))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_input = []\n",
    "durations_input = []\n",
    "phrases_input = []\n",
    "\n",
    "for piece in data:\n",
    "    notes = piece[0]\n",
    "    notes_input.append(129) # START = 129\n",
    "    notes_input.extend(notes)\n",
    "\n",
    "    durations = piece[1]\n",
    "    durations_input.append(0)\n",
    "    durations_input.extend(durations)\n",
    "\n",
    "    phrases = piece[2]\n",
    "    phrases_input.append(0)\n",
    "    phrases_input.extend(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the notes_input: 282505\n",
      "Twenty first elements: [129, 55, 60, 60, 60, 60, 60, 62, 64, 64, 64, 67, 62, 128, 67, 60, 128, 55, 60, 60]\n",
      "Length of the durations_input: 282505\n",
      "Twenty first elements: [0, 0.5, 0.5, 0.5, 0.375, 0.125, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5]\n",
      "Length of the phrases_input: 282505\n",
      "Twenty first elements: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the notes_input: {}\".format(len(notes_input)))\n",
    "print(\"Twenty first elements: {}\".format(notes_input[:20]))\n",
    "print(\"Length of the durations_input: {}\".format(len(durations_input)))\n",
    "print(\"Twenty first elements: {}\".format(durations_input[:20]))\n",
    "print(\"Length of the phrases_input: {}\".format(len(phrases_input)))\n",
    "print(\"Twenty first elements: {}\".format(phrases_input[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_to_int = {}\n",
    "int_to_duration = {}\n",
    "notes_to_int = {}\n",
    "int_to_notes = {}\n",
    "phrases_to_int = {}\n",
    "int_to_phrases = {}\n",
    "for index, duration in enumerate(sorted(set(durations_input))):\n",
    "    durations_to_int[duration] = index\n",
    "    int_to_duration[index] = duration\n",
    "\n",
    "for index, note in enumerate(sorted(set(notes_input))):\n",
    "    notes_to_int[note] = index\n",
    "    int_to_notes[index] = note\n",
    "\n",
    "for index, phrase in enumerate(sorted(set(phrases_input))):\n",
    "    phrases_to_int[phrase] = index\n",
    "    int_to_phrases[index] = phrase\n",
    "\n",
    "durations_network_input = [ durations_to_int[duration] for duration in durations_input ]\n",
    "notes_network_input = [ notes_to_int[note] for note in notes_input ]\n",
    "phrases_network_input = [ phrases_to_int[phrase] for phrase in phrases_input ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0.00390625,\n",
       " 2: 0.125,\n",
       " 3: Fraction(1, 6),\n",
       " 4: 0.25,\n",
       " 5: Fraction(1, 3),\n",
       " 6: 0.375,\n",
       " 7: 0.5,\n",
       " 8: Fraction(2, 3),\n",
       " 9: 0.75,\n",
       " 10: 1.0,\n",
       " 11: Fraction(4, 3),\n",
       " 12: 1.5,\n",
       " 13: 2.0,\n",
       " 14: 3.0,\n",
       " 15: 4.0,\n",
       " 16: 6.0,\n",
       " 17: 8.0,\n",
       " 18: 12.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the notes_input: 282505\n",
      "Twenty first elements: [45, 10, 15, 15, 15, 15, 15, 17, 19, 19, 19, 22, 17, 44, 22, 15, 44, 10, 15, 15]\n",
      "Length of the durations_input: 282505\n",
      "Twenty first elements: [0, 7, 7, 7, 6, 2, 4, 4, 7, 7, 7, 7, 10, 7, 7, 10, 7, 7, 7, 7]\n",
      "Length of the phrases_input: 282505\n",
      "Twenty first elements: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the notes_input: {}\".format(len(notes_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(notes_network_input[:20]))\n",
    "print(\"Length of the durations_input: {}\".format(len(durations_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(durations_network_input[:20]))\n",
    "print(\"Length of the phrases_input: {}\".format(len(phrases_network_input)))\n",
    "print(\"Twenty first elements: {}\".format(phrases_network_input[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = len(notes_to_int)\n",
    "n_durations = len(durations_to_int)\n",
    "n_phrases = len(phrases_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct notes: 46\n",
      "Number of distinct durations: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of distinct notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct durations: {}\".format(n_durations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary.pkl', 'wb') as file:\n",
    "    dictionary = { \"durations_to_int\" : durations_to_int, \"int_to_duration\" : int_to_duration, \"notes_to_int\" : notes_to_int, \"int_to_notes\" : int_to_notes, \"phrases_to_int\" : phrases_to_int, \"int_to_phrases\" : int_to_phrases }\n",
    "    # A new file will be created\n",
    "    pickle.dump(dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import note, chord\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from models.RNNAttentionApproach2 import prepare_sequences, create_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 32\n",
    "network_input, network_output = prepare_sequences(notes_network_input, durations_network_input, phrases_network_input, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note input\n",
      "[45 10 15 15 15 15 15 17 19 19 19 22 17 44 22 15 44 10 15 15 15 15 17 19\n",
      " 19 19 22 17 44 22 15 44]\n",
      "duration input\n",
      "[ 0  7  7  7  6  2  4  4  7  7  7  7 10  7  7 10  7  7  7  7  7  4  4  7\n",
      "  7  7  7 10  7  7 10  7]\n",
      "phrases_output\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('note input')\n",
    "print(network_input[0][0])\n",
    "print('duration input')\n",
    "print(network_input[1][0])\n",
    "print('phrases_output')\n",
    "print(network_output[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 20:51:46.600514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 20:51:46.600956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 20:51:46.601027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 20:51:48.546941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 20:51:48.547098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 20:51:48.547113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-27 20:51:48.547146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 20:51:48.547198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-04-27 20:51:48.999936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 20:51:49.002868: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 20:51:49.005128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    4600        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    1900        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, 200)    0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, None, 256)    467968      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, None, 256)    525312      ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 1)      257         ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, None)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None)         0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 256, None)    0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, None, 256)    0           ['repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, None, 256)    0           ['lstm_1[0][0]',                 \n",
      "                                                                  'permute[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 256)          0           ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " phrase (Dense)                 (None, 2)            514         ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,000,551\n",
      "Trainable params: 1,000,551\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 20:51:49.229282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 20:51:49.231832: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 20:51:49.234503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "/root/miniconda3/envs/tf/lib/python3.11/site-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "embed_size = 100\n",
    "rnn_units = 256\n",
    "use_attention = True\n",
    "model, att_model = create_network(n_notes, n_durations, n_phrases, embed_size, rnn_units, use_attention)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 20:51:49.518110: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 57850368 exceeds 10% of free system memory.\n",
      "2023-04-27 20:51:49.670037: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 57850368 exceeds 10% of free system memory.\n",
      "2023-04-27 20:51:49.848978: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 57850368 exceeds 10% of free system memory.\n",
      "2023-04-27 20:51:49.959434: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 57850368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 20:51:50.936909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 20:51:50.949710: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 20:51:50.954978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 20:51:51.518062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 20:51:51.526143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 20:51:51.529214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 20:51:53.402805: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 20:51:53.406237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 20:51:53.408583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 20:51:53.725634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 20:51:53.728011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 20:51:53.734071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 20:52:20.088393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-27 20:52:22.888496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7062/7062 [==============================] - ETA: 0s - loss: 0.3529"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 20:56:13.816366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 20:56:13.818813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 20:56:13.820447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-27 20:56:14.414494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-27 20:56:14.419432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-27 20:56:14.422845: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7062/7062 [==============================] - 289s 36ms/step - loss: 0.3529 - val_loss: 0.3381\n",
      "Epoch 2/2000000\n",
      "7062/7062 [==============================] - 238s 34ms/step - loss: 0.3159 - val_loss: 0.2997\n",
      "Epoch 3/2000000\n",
      "7062/7062 [==============================] - 196s 28ms/step - loss: 0.2906 - val_loss: 0.2753\n",
      "Epoch 4/2000000\n",
      "7062/7062 [==============================] - 197s 28ms/step - loss: 0.2737 - val_loss: 0.2633\n",
      "Epoch 5/2000000\n",
      "7062/7062 [==============================] - 199s 28ms/step - loss: 0.2549 - val_loss: 0.2561\n",
      "Epoch 6/2000000\n",
      "7062/7062 [==============================] - 211s 30ms/step - loss: 0.2446 - val_loss: 0.2492\n",
      "Epoch 7/2000000\n",
      "7062/7062 [==============================] - 203s 29ms/step - loss: 0.2372 - val_loss: 0.2413\n",
      "Epoch 8/2000000\n",
      "7062/7062 [==============================] - 221s 31ms/step - loss: 0.2320 - val_loss: 0.2482\n",
      "Epoch 9/2000000\n",
      "7062/7062 [==============================] - 206s 29ms/step - loss: 0.2298 - val_loss: 0.2547\n",
      "Epoch 10/2000000\n",
      "7062/7062 [==============================] - 277s 39ms/step - loss: 0.2267 - val_loss: 0.2428\n",
      "Epoch 11/2000000\n",
      "7062/7062 [==============================] - 260s 37ms/step - loss: 0.2262 - val_loss: 0.2394\n",
      "Epoch 12/2000000\n",
      "7062/7062 [==============================] - 351s 50ms/step - loss: 0.2267 - val_loss: 0.2410\n",
      "Epoch 13/2000000\n",
      "7062/7062 [==============================] - 383s 54ms/step - loss: 0.2265 - val_loss: 0.2405\n",
      "Epoch 14/2000000\n",
      "7062/7062 [==============================] - 334s 47ms/step - loss: 0.2256 - val_loss: 0.2495\n",
      "Epoch 15/2000000\n",
      "7062/7062 [==============================] - 337s 48ms/step - loss: 0.2271 - val_loss: 0.2494\n",
      "Epoch 16/2000000\n",
      "7062/7062 [==============================] - 356s 50ms/step - loss: 0.2301 - val_loss: 0.2451\n",
      "Epoch 17/2000000\n",
      "7062/7062 [==============================] - 359s 51ms/step - loss: 0.2340 - val_loss: 0.2505\n",
      "Epoch 18/2000000\n",
      "7062/7062 [==============================] - 328s 46ms/step - loss: 0.2321 - val_loss: 0.2494\n",
      "Epoch 19/2000000\n",
      "7062/7062 [==============================] - 169s 24ms/step - loss: 0.2360 - val_loss: 0.2566\n",
      "Epoch 20/2000000\n",
      "7062/7062 [==============================] - 272s 39ms/step - loss: 0.2474 - val_loss: 0.2687\n",
      "Epoch 21/2000000\n",
      "7062/7062 [==============================] - 402s 57ms/step - loss: 0.2476 - val_loss: 0.2604\n",
      "Epoch 22/2000000\n",
      "7062/7062 [==============================] - 3050s 432ms/step - loss: 0.2512 - val_loss: 0.2565\n",
      "Epoch 23/2000000\n",
      "7062/7062 [==============================] - 3536s 501ms/step - loss: 0.2548 - val_loss: 0.2613\n",
      "Epoch 24/2000000\n",
      "7062/7062 [==============================] - 229s 32ms/step - loss: 0.2556 - val_loss: 0.2622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8732938690>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "weights_folder = \"weights\" #os.path.join(run_folder, 'weights')\n",
    "# model.load_weights(os.path.join(weights_folder, \"weights.h5\"))\n",
    "\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 10\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint1\n",
    "    , checkpoint2\n",
    "    , early_stopping\n",
    " ]\n",
    "\n",
    "model.save_weights(os.path.join(weights_folder, \"weights.h5\"))\n",
    "model.fit(network_input, network_output\n",
    "          , epochs=2000000, batch_size=32\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
